{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('text: ', example.numpy())\n",
    "    print('label: ', label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>\n",
      "<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b\"I don't want to go too far into detail, because I can't really justify wasting much time on reviewing this film, but I had to give an alternate opinion to hopefully help people avoid the movie. The animation is crud and the story alternates between boring/pointless to extremely irritating. The humor was completely lost on the audience, and yes - Ghost in the Shell fans, this is NOT an action sci-fi or anything like that - its an attempt at slapstick comedy, and the humor just did not work after being translated. It was a total chore to watch this movie, and horrible way for me to kick off the film fest, especially considering how excited I was and how open I was for anything - I wasn't expecting a Ghost in the Shell sequel, but I was expecting something entertaining, and it simply didn't achieve this. Yaaawwnnn... Rent Kino's Journey instead.\"\n",
      " b\"I never had an inkling while watching the movie that it was meant for the idiot box. I always thought that this was some very good successful movie of the late 90's. But after I saw on the internet that this was meant for the TV, I was shocked because for a television film, it is absolutely fantastic!<br /><br />The thing that mostly concerned me was the length. I felt that the one on one battle scene should've been removed as it was completely unnecessary. Also, it began to drag towards the end as it seemed as if the adventure was never going to end. <br /><br />On the plus side, there is a strong, very interesting and captivating plot with magnificent performances by everyone. I just felt that Patrik Frayze looked a bit haggard. I also felt that Gogool, who looked dementing turned a bit stupid at some scenes.<br /><br />I was delighted by the beautiful landscapes of Africa. Also, the first half of the movie would have made me give this movie a 9. Still, its a great film for the television. 8 out of 10.\"\n",
      " b'I love watching early colour films - you mean those 40s clothes weren\\'t all grey? <br /><br />Margaret Rutherford dominates this movie. Her \"eccentric\" garb is actually rather attractive and yes, she has an amazing hourglass figure. But I feel she was given her head rather too much. She probably developed this characterisation over many performances, and nobody told her \"If it gets a laugh, leave it out.\" She does too much deranged fooling about when she\\'s supposed to be surprisingly down to earth. The Madame Arcati joke is that mediums were usually portrayed as wispy females in long drapery. Arcati behaves like a retired headmistress (We\\'ll really put our backs into it!). The contrast between her breezy, commonplace manner and her wacky beliefs isn\\'t really brought out.<br /><br />Just because all the actors are English (apart from Cummings), the Americans feel they have to use the words \"Brit\", \"stiff\", \"lip\" and \"upper\". Oh, give it a rest! The three main characters lose their tempers constantly and make risqu\\xc3\\xa9 remarks (Did he make love to you? Yes, but very discreetly - he was in the cavalry!).']\n",
      "\n",
      "labels:  [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  90, 178, ...,   0,   0,   0],\n",
       "       [ 10, 110,  67, ...,   0,   0,   0],\n",
       "       [ 10, 116, 147, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b\"I don't want to go too far into detail, because I can't really justify wasting much time on reviewing this film, but I had to give an alternate opinion to hopefully help people avoid the movie. The animation is crud and the story alternates between boring/pointless to extremely irritating. The humor was completely lost on the audience, and yes - Ghost in the Shell fans, this is NOT an action sci-fi or anything like that - its an attempt at slapstick comedy, and the humor just did not work after being translated. It was a total chore to watch this movie, and horrible way for me to kick off the film fest, especially considering how excited I was and how open I was for anything - I wasn't expecting a Ghost in the Shell sequel, but I was expecting something entertaining, and it simply didn't achieve this. Yaaawwnnn... Rent Kino's Journey instead.\"\n",
      "Round-trip:  i dont want to go too far into [UNK] because i cant really [UNK] [UNK] much time on [UNK] this film but i had to give an [UNK] opinion to [UNK] help people avoid the movie the animation is [UNK] and the story [UNK] between [UNK] to extremely [UNK] the humor was completely lost on the audience and yes [UNK] in the [UNK] fans this is not an action scifi or anything like that its an attempt at [UNK] comedy and the humor just did not work after being [UNK] it was a total [UNK] to watch this movie and horrible way for me to [UNK] off the film [UNK] especially [UNK] how [UNK] i was and how open i was for anything i wasnt expecting a [UNK] in the [UNK] sequel but i was expecting something entertaining and it simply didnt [UNK] this [UNK] rent [UNK] [UNK] instead                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "\n",
      "Original:  b\"I never had an inkling while watching the movie that it was meant for the idiot box. I always thought that this was some very good successful movie of the late 90's. But after I saw on the internet that this was meant for the TV, I was shocked because for a television film, it is absolutely fantastic!<br /><br />The thing that mostly concerned me was the length. I felt that the one on one battle scene should've been removed as it was completely unnecessary. Also, it began to drag towards the end as it seemed as if the adventure was never going to end. <br /><br />On the plus side, there is a strong, very interesting and captivating plot with magnificent performances by everyone. I just felt that Patrik Frayze looked a bit haggard. I also felt that Gogool, who looked dementing turned a bit stupid at some scenes.<br /><br />I was delighted by the beautiful landscapes of Africa. Also, the first half of the movie would have made me give this movie a 9. Still, its a great film for the television. 8 out of 10.\"\n",
      "Round-trip:  i never had an [UNK] while watching the movie that it was meant for the [UNK] [UNK] i always thought that this was some very good [UNK] movie of the late [UNK] but after i saw on the [UNK] that this was meant for the tv i was [UNK] because for a television film it is absolutely [UNK] br the thing that mostly [UNK] me was the [UNK] i felt that the one on one battle scene [UNK] been [UNK] as it was completely [UNK] also it [UNK] to [UNK] towards the end as it seemed as if the [UNK] was never going to end br br on the plus side there is a strong very interesting and [UNK] plot with [UNK] performances by everyone i just felt that [UNK] [UNK] looked a bit [UNK] i also felt that [UNK] who looked [UNK] turned a bit stupid at some [UNK] br i was [UNK] by the beautiful [UNK] of [UNK] also the first half of the movie would have made me give this movie a [UNK] still its a great film for the television [UNK] out of 10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "Original:  b'I love watching early colour films - you mean those 40s clothes weren\\'t all grey? <br /><br />Margaret Rutherford dominates this movie. Her \"eccentric\" garb is actually rather attractive and yes, she has an amazing hourglass figure. But I feel she was given her head rather too much. She probably developed this characterisation over many performances, and nobody told her \"If it gets a laugh, leave it out.\" She does too much deranged fooling about when she\\'s supposed to be surprisingly down to earth. The Madame Arcati joke is that mediums were usually portrayed as wispy females in long drapery. Arcati behaves like a retired headmistress (We\\'ll really put our backs into it!). The contrast between her breezy, commonplace manner and her wacky beliefs isn\\'t really brought out.<br /><br />Just because all the actors are English (apart from Cummings), the Americans feel they have to use the words \"Brit\", \"stiff\", \"lip\" and \"upper\". Oh, give it a rest! The three main characters lose their tempers constantly and make risqu\\xc3\\xa9 remarks (Did he make love to you? Yes, but very discreetly - he was in the cavalry!).'\n",
      "Round-trip:  i love watching early [UNK] films you mean those [UNK] [UNK] [UNK] all [UNK] br br [UNK] [UNK] [UNK] this movie her [UNK] [UNK] is actually rather [UNK] and yes she has an amazing [UNK] figure but i feel she was given her head rather too much she probably [UNK] this [UNK] over many performances and [UNK] told her if it gets a laugh leave it out she does too much [UNK] [UNK] about when shes supposed to be [UNK] down to earth the [UNK] [UNK] joke is that [UNK] were usually portrayed as [UNK] [UNK] in long [UNK] [UNK] [UNK] like a [UNK] [UNK] well really put our [UNK] into it the [UNK] between her [UNK] [UNK] [UNK] and her [UNK] [UNK] isnt really brought [UNK] br just because all the actors are english apart from [UNK] the [UNK] feel they have to use the words [UNK] [UNK] [UNK] and [UNK] oh give it a rest the three main characters [UNK] their [UNK] [UNK] and make [UNK] [UNK] did he make love to you yes but very [UNK] he was in the [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "    print(\"Original: \", example[n].numpy())\n",
    "    print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0025772]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0025772]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text with padding\n",
    "\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 263s 662ms/step - loss: 0.6821 - accuracy: 0.5111 - val_loss: 0.5469 - val_accuracy: 0.7339\n",
      "Epoch 2/10\n",
      " 71/391 [====>.........................] - ETA: 3:23 - loss: 0.5363 - accuracy: 0.7257"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None,1)\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = ('The movie was not good. The animation and the graphics '\n",
    "                    'were terrible. I would not recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
